# Education Dataset Analysis Pipeline: Walkthrough \#1

``` {r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
```

## Background

In the 2015-2016 and 2016-2017 school years, researchers carried out a study on
students' motivation to learn in online science classes. The online science
classes were part of a statewide online course provider designed to supplement
(and not replace) students' enrollment in their local school. For example,
students may choose to enroll in an online physics class because one was not
offered at their school (or they were not able to take it given their schedule).

The study involved a number of different data sources which were explored to
understand students' motivation:

1.  A self-report survey for three distinct but related aspects of students'
    motivation
2.  Log-trace data, such as data output from the learning management system
3.  Discussion board data
4.  Achievement-related (i.e., final grade) data

First, these different data sources will be described in terms of how they were
provided by the school.

### Data source \#1: Self-report survey

This was data collected before the start of the course via self-report survey.
The survey included 10 items, each corresponding to one of three *measures*,
namely, for interest, utility value, and perceived competence:

1.  I think this course is an interesting subject. (Interest)
2.  What I am learning in this class is relevant to my life. (Utility value)
3.  I consider this topic to be one of my best subjects. (Perceived competence)
4.  I am not interested in this course. (Interest - reverse coded)
5.  I think I will like learning about this topic. (Interest)
6.  I think what we are studying in this course is useful for me to know.
    (Utility value)
7.  I don’t feel comfortable when it comes to answering questions in this area.
    (Perceived competence)
8.  I think this subject is interesting. (Interest)
9.  I find the content of this course to be personally meaningful. (Utility
    value)
10. I’ve always wanted to learn more about this subject. (Interest)

### Data source \#2: Log-trace data

*Log-trace data* is data generated from our interactions with digital
technologies, such as archived data from social media postings (see Chapter XXX
and XXX). In education, an increasingly common source of log-trace data is that
generated from interactions with learning management systems and other digital
tools (Lazer et al., 2009; Salganik, 2018; Welser, Smith, Fisher, &
Gleave, 2008). The data for this walk-through is a *summary of* log-trace data,
namely, the number of minutes students spent on the course. Thus, while this
data is rich, you can imagine even more complex sources of log-trace data (i.e.
timestamps associated with when students started and stopped accessing the
course!).

### Data source \#3: Achievement-related and gradebook data

This is a common source of data, namely, one associated with graded assignments
students completed. In this walkthrough, we just examine students' final grade.

### Data source \#4: Discussion board data

Discussion board data is both rich and unstructured, in that it is primarily in
the form of written text. We collected discussion board data, too, and highlight
this as a potentially very rich data source.

## Processing the data

This analysis uses R packages, which are collections of R code that help users
code more efficiently, as you wil recall from Chapter INTRODUCTORY. We load
these packages with the function `library`. In particular, the packages we'll
use will help us load Excel files, organize the structure of the data, work with
dates in the data, and navigate file directories.

``` {r, loading-packages}
library(readxl)
library(tidyverse)
library(lubridate)
library(here)
```

This code chunk loads the log trace data using the `read_csv` function. Note
that we call `read_csv` three times, once for each of the three logtrace
datasets. We assign each of the datasets a name using `<-`.

``` {r}
# Gradebook and log-trace data for F15 and S16 semesters
s12_course_data <- read_csv(
  here(
    "data", 
    "online-science-motivation", 
    "raw", 
    "s12-course-data.csv"
  )
)
```

# Pre-survey for the F15 and S16 semesters

s12\_pre\_survey \<- read\_csv( here( "data", "online-science-motivation",
"raw", "s12-pre-survey.csv" ) )

# Log-trace data for F15 and S16 semesters - this is for time spent

s12\_time\_spent \<- read\_csv( here( "data", "online-science-motivation",
"raw", "s12-course-minutes.csv" ) )

``` 
```

## Viewing the data

Now that we've successfully loaded all three logtrace datasets, we can visually
inspect the data by typing the names that we assigned to each dataset.

``` {r}
s12_pre_survey 
s12_course_data
s12_time_spent
```

## Processing the pre-survey data

Often, survey data needs to be processed in order to be (most) useful. Here, we
process the self-report items into three scales, for: interest, self-efficacy,
and utility value. We do this by

  - Renaming the question variables to something more managable
  - Reversing the response scales on questions 4 and 7
  - Categorizing each question into a measure
  - Computing the mean of each measure

Let's take these steps in order:

1.  Rename the question columns to something much simpler:

``` {r}
s12_pre_survey  <- s12_pre_survey  %>%
  # Rename the qustions something easier to work with because R is case sensitive
  # and working with variable names in mix case is prone to error
  rename(q1 = Q1MaincellgroupRow1,
         q2 = Q1MaincellgroupRow2,
         q3 = Q1MaincellgroupRow3,
         q4 = Q1MaincellgroupRow4,
         q5 = Q1MaincellgroupRow5,
         q6 = Q1MaincellgroupRow6,
         q7 = Q1MaincellgroupRow7,
         q8 = Q1MaincellgroupRow8,
         q9 = Q1MaincellgroupRow9,
         q10 = Q1MaincellgroupRow10) %>% 
  # Convert all question responses to numeric
  mutate_at(vars(q1:q10), funs(as.numeric))
```

2.  Next we'll reverse the scale of the survey responses on questions 4 and 7 so
    the responses for all questions can be interpreted in the same way. Rather
    than write a lot of code once to reverse the scales for question 4 then
    writing it again to reverse the scales on question 7, we'll build a function
    that does that job for us. Then we'll use the same function for question 4
    and question 7. This will result in much less code, plus it will make it
    easier for us to change in the future.

``` {r}
# This part of the code is where we write the function:
```

# Function for reversing scales

reverse\_scale \<- function(question) {

# Reverses the response scales for consistency

# Args:

# question: survey question

# Returns: a numeric converted response

# Note: even though 3 is not transformed, case\_when expects a match for all

# possible conditions, so it's best practice to label each possible input

# and use TRUE \~ as the final statement returning NA for unexpected inputs

x \<- case\_when(question == 1 \~ 5, question == 2 \~ 4, question == 4 \~ 2,
question == 5 \~ 1, question == 3 \~ 3, TRUE \~ NA\_real\_) x }

# And here's where we use that function to reverse the scales

# Reverse scale for questions 4 and 7

s12\_pre\_survey \<- s12\_pre\_survey %\>% mutate(q4 = reverse\_scale(q4), q7 =
reverse\_scale(q7))

``` 
```

3.  We'll accomplish the last two steps in one chunk of code. First we'll create
    a column called `measure` and we'll fill that column with one of three
    question categories:

  - `int`: interest
  - `uv`: utility value
  - `pc`: self efficacy

After that we'll find the mean response of each category using `mean` function.

``` {r}
# Add measure variable 
s12_measure_mean <- s12_pre_survey %>% 
  # Gather questions and responses 
  gather(question, response, c(q1:q10)) %>% 
  mutate(
    # Here's where we make the column of question categories 
    measure = case_when(
      question %in% c("q1", "q4", "q5", "q8", "q10") ~ "int", 
      question %in% c("q2", "q6", "q9") ~ "uv", 
      question %in% c("q3", "q7") ~ "pc", 
      TRUE ~ NA_character_
    )) %>% 
  group_by(measure) %>% 
  summarise(
    # Here's where we compute the mean of the responses 
    # Mean response for each measure
    mean_response = mean(response, na.rm = TRUE), 
    # Percent of each measure that had NAs in the response field
    percent_NA = mean(is.na(response))
  )
```

s12\_measure\_mean

``` 
```

We will use a similar process later to calculate these variables' correlations.

## Processing the course data

We also can process the course data in order to create new variables which we
can use in analyses. This led to pulling out the subject, semester, and section
from the course ID; variables that we can use later on.

``` {r}
# split course section into components
s12_course_data <- s12_course_data %>%
  separate(col = CourseSectionOrigID,
           into = c('subject', 'semester', 'section'),
           sep = '-',
           remove = FALSE)
```

## Joining the data

To join the course data and pre-survey data, we need to create similar *keys*.
In other words, our goal here is to have one variable that matches across both
datasets, so that we can merge the datasets on the basis of that variable.

For these data, both have variables for the course and the student, though they
have different names in each. Our first goal will be to rename two variables in
each of our datasets so that they will match. One variable will correspond to
the course, and the other will correspond to the student. We are not changing
anything in the data itself at this step - instead, we are just cleaning it up
so that we can look at the data all in one place.

Let's start with the pre-survey data. We will rename RespondentID and
opdata\_CourseID to be student\_id and course\_id, respectively.

``` {r}
s12_pre_survey <- s12_pre_survey %>% 
  rename(student_id = RespondentId,
         course_id = opdata_CourseID)
```

s12\_pre\_survey

``` 
```

Looks better now!

Let's proceed to the course data. Our goal is to rename two variables that
correspond to the course and the student so that we can match with the other
variables we just created for the pre-survey data.

``` {r}
s12_course_data <- s12_course_data %>% 
  rename(student_id = Bb_UserPK,
         course_id = CourseSectionOrigID)
```

Now that we have two variables that are consistent across both datasets - we
have called them "course\_id" and "student\_id" - we can join these using the
**dplyr** function, `left_join()`. Let's save our joined data as a new object
called "dat."

``` {r}
dat <- left_join(s12_course_data, 
                 s12_pre_survey, 
                 by = c("student_id", "course_id"))
```

dat

``` 
```

Just one more data frame to merge:

``` {r}
s12_time_spent <- s12_time_spent %>%
  rename(student_id = Bb_UserPK, 
         course_id = CourseSectionOrigID)
```

s12\_time\_spent \<- s12\_time\_spent %\>% mutate(student\_id =
as.integer(student\_id))

dat \<- dat %\>% left\_join(s12\_time\_spent, by = c("student\_id",
"course\_id"))

``` 
```

Note that they're now combined, even though the course data has many more rows:
The pre\_survey data has been joined for each student by course combination.

We have a pretty large data frame! Let's take a quick look.

``` {r}
dat
```

It looks like we have nearly 30,000 observations from 30 variables.

There is one last step to take. Were we interested in a fine-grained analysis of
how students performed (according to the teacher) on different assignments (see
the `Gradebook_Item` column), we would keep all (29,711 rows of) the data. But,
our goal (for now) is more modest: to calculate the percentage of points
students earned as a measure of their final grade (noting that the teacher may
have assigned a different grade--or weighted their grades in ways not reflected
through the points).

``` {r}
dat <- dat %>% 
  group_by(student_id, course_id) %>% 
  mutate(Points_Earned = as.integer(Points_Earned)) %>% 
  summarize(total_points_possible = sum(Points_Possible, na.rm = TRUE),
            total_points_earned = sum(Points_Earned, na.rm = TRUE)) %>% 
  mutate(percentage_earned = total_points_earned/total_points_possible) %>% 
  ungroup() %>% 
  left_join(dat) # note that we join this back to the original data frame to retain all of the variables
```

## Finding distinct cases at the student-level

This last step calculated a new column, for the percentage of points each
student earned. That value is the same for the same student (an easy way we
would potentially use to check this is `View()`, i.e., `View(dat)`).
But--because we are not carrying out a finer-grained analysis using the
`Gradebook_Item`--the duplicate rows are not necessary. We only want variables
at the student-level (and not at the level of different gradebook items). We can
do this using the `distinct()` function. This function takes the name of the
data frame and the name of the variables used to determine what counts as a
unique case. Another thing to note about `distinct()` is that it will only
return the variable(s) (we note that you can pass more than one variable to
`distinct()`) you used to determine uniqueness, *unless* you include the
argument `.keep_all = TRUE`. For the sake of making it very easy to view the
output, we omit this argument (only for now).

Were we to run `distinct(dat, Gradebook_Item)`, what do you think would be
returned?

``` {r}
distinct(dat, Gradebook_Item)
```

What is every distinct gradebook item is what is returned. You might be
wondering (as we were) whether some gradebook items have the same values across
courses; we can return the unique *combination* of courses and gradebook items
by simply adding another variable to `distinct()`:

``` {r}
distinct(dat, course_id, Gradebook_Item)
```

It looks like *a lot* of gradebook items were repeated - likely across the
different sections of the same course (we would be curious to hear what you find
if you investigate this!).

Let's use what we just did, but to find the unique values at the student-level.
Thus, instead of exploring unique gradebook items, we will explore unique
students (still accounting for the course, as students could enroll in more than
one course.) This time, we will add the `keep_all = TRUE` argument.

``` {r}
dat <- distinct(dat, course_id, student_id, .keep_all = TRUE)
```

This is a much smaller data frame - with one row for each sudnet in the course
(instead of the 29,701 rows which we would be interested in were we analyzing
this data at the level of specific students' grades for specific gradebook
items). Now that our data are ready to go, we can start to ask some questions of
the data,

## Visualizations and Models

### The relationship between time spent on course and percentage of points earned

One thing we might be wondering is how time spent on course is related to
students' final grade.

<!-- This is really trivial and obvious; need a new/better relationship -->

``` {r}
ggplot(dat, aes(x = TimeSpent, y = percentage_earned)) +
  geom_point() 
```

There appears to be *some* relationship. What if we added a line of best fit - a
linear model?

``` {r}
ggplot(dat, aes(x = TimeSpent, y = percentage_earned)) +
  geom_point() + 
  geom_smooth(method = "lm")
```

So, it appeares that the more time students spent on the course, the more points
they earned.

## Linear model (regression)

We can find out exactly what the relationship is using a linear model. We also
discuss linear models in walkthrough XXX.

Here, we predict `percentage_earned`, or the percentage of the total points that
are possible for a student to earn. Here, percentage earned is the dependent, or
*y*-variable, and so we enter it first, after the `lm()` command, before the
tilde (`~`) symbol. To the right of the tilde is one independent variable,
`TimeSpent`, or the time that students spent on the course. We also pass the
data frame, `dat`. At this point, we're ready to run the model. Let's run this
line of code and save the results to an object - we chose `m_linear`, but any
name will work, as well as the `summary()` function on the output.

``` {r}
m_linear <- lm(percentage_earned ~ TimeSpent, data = dat)
sjPlot::tab_model(m_linear)
```

Another way that we can generate table output is with a function from the
`sjPlot` package, `tab_model`.

``` {r}
sjPlot::tab_model(m_linear)
```

This will work well for R Markdown documents (or simply to interpet the model in
R). If you want to save the model for use in a Word document, the
[apaTables](https://cran.r-project.org/web/packages/apaTables/vignettes/apaTables.html)
package may be helpful; just pass the name of the regression model, like we did
with `sjPlot::tab_model()`, as well as a file name that ends in `.doc` to the
`filename` argument, i.e.:

``` {r, eval = FALSE}
library(apaTables)
apa.reg.table(m_summary, filename = "m_summary_regression_table.doc")
```

<!-- Wonder if we also want to show how to do correlation tables with this package -->

You might be wondering what else the apaTables package does; we encourage you to
read more about the package here:
<https://cran.r-project.org/web/packages/apaTables/index.html>. The vignette is
especially helpful. One function that may be useful for writing manuscripts is
the following function for creating correlation tables; the function takes, as
an input, a data frame with the variables for which you wish to calculate
correlations. We will create the same measures (based on the survey items) that
we used earlier to understand how the percentage of points earned is related to
these measures (and how all of the variables relate to one another:

``` {r}
s12_measure_mean <- s12_pre_survey %>% 
  # Gather questions and responses 
  gather(question, response, c(q1:q10)) %>% 
  mutate(
    # Here's where we make the column of question categories 
    measure = case_when(
      question %in% c("q1", "q4", "q5", "q8", "q10") ~ "int", 
      question %in% c("q2", "q6", "q9") ~ "uv", 
      question %in% c("q3", "q7") ~ "pc", 
      TRUE ~ NA_character_
    )) %>% 
```
  
select(percentage\_earned, int, uv, pc) apa.cor.table()

``` 
```

The time spent variable is on a very large scale (minutes); what if we transform
it to represent the number of hours that students spent on the course into
hours? Let's use the `mutate()` function we used earlier. We'll end the variable
name in `_hours`, to represent what this variable means.

``` {r}
dat <- dat %>% mutate(TimeSpent_hours = TimeSpent/60)
m_linear_1 <- lm(percentage_datearned ~ TimeSpent_hours, data = dat)
sjPlot::tab_model(m_linear_1)
```

The scale stil does not seem quite right. What if we standardized the variable
to have a mean of zero and a standard deviation of one?

``` {r}
dat <- dat %>% mutate(TimeSpent_std = scale(TimeSpent))
m_linear_2 <- lm(percentage_earned ~ TimeSpent_std, data = dat)
sjPlot::tab_model(m_linear_2)
```

That seems to make more sense - although, there is a different interpretation
now for the time spent variable: for every one standard deviation increase in
the amount of time spent on the course, the percentage of points a student earns
increases by .11, or 11 percentage points.

Let's extend our regression model: what other variables may matter? Perhaps
there are differences based on the subject of the course. We can add subject as
a variable easily:

``` {r}
m_linear_3 <- lm(percentage_earned ~ scale(TimeSpent) + subject, data = dat)
```

We can use `sjPlot::tab_model()` once again to view the results:

``` {r}
sjPlot::tab_model(m_linear_3)
```

It looks like subject `FrSc` - forensic science - and subject `Ocn` -
oceanography - are associated with a higher percentage of points earned,
overall.

## What is next?

In the follow-up to this walkthrough (see Chapter XXX), we will focus on
visualizing and then modeling the data using an advanced methodological
technique, multi-level models. Before we go, let's save the data we processed.

<!-- Not sure how to deal with these paths in the book?!? also the name of the file -->

``` {r, eval = FALSE}
write_csv(dat, "data/online-science-motivation/processed/dat.csv")
```
