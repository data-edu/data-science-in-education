# Introducing data science tools to your education job {#c15}

**Abstract**
This chapter explores using the tools of data science in an education job. Learning techniques like cleaning data, visualizing data, and modeling data are the first part of integrating data science tools in an education job. The next part is learning to apply these skills in practical day to day work. Using examples in R, this chapter explains how statistical programming increases the speed and scale of data work. Practicing these skills in day to day work will empower staff to get the most out of their training and develop a meaningful role as a data scientist in education. Data science tools explored in this chapter include empathy, collaboration, and adopting an entrepreneurial mindset.


## Chapter overview

The purpose of this section is to explore taking newfound data science skills into your workplace. In particular, you'll learn to find practical ways to use your skills, encourage your coworkers to be better users of data, and develop meaningful analytic routines. Whether you are a consultant working with a community college, an administrator leading teachers at a high school, or a university department chair, you'll eventually begin turning what you've learned in this book into meaningful activities. 

We'll discuss this topic in two parts: bringing your organization the gift of speed and scale, and the importance of connecting well with others. Then we'll close this chapter by discussing ways that K-12 teachers in particular can engage a work culture that is new to using data in decision making.

## The gift of speed and scale

The power of doing data analysis with a programming language like R comes from two features: (1) a massive boost in the speed of your work and (2) a massive boost in the volume of data you analyze. Here are approaches to introducing data science to your job that focus on practical applications of speed and scale. 

### Working with data faster

Data analysts who use an efficient analytic process understand their clients' questions faster because they rapidly cycle through analysis and discussion. As a result, they quickly accumulate skill and experience because each project includes many cycles of data analysis. 

Lots of data scientists have built and shared analytic routines. Roger Peng and Elizabeth Matsui discuss epicycles of analysis in their book [The Art of Data Science](https://bookdown.org/rdpeng/artofdatascience/epicycles-of-analysis.html). In their book [R for Data Science](https://r4ds.had.co.nz/explore-intro.html), Garrett Grolemund and Hadley Wickham demonstrate a routine for data exploration. 

What's important is to pick a routine that keeps you focused on repeatable steps. When the problem space is unclear, as it often is education data analysis, the path from research question to analysis is full of detours and distractions. Having a routine that points you to the next immediate analytic step helps you start quickly. And many quick starts results in a lot of analysis.

Moving through data analysis systematically and rapidly has other benefits. It fuels the creativity required to understand problems in education and the imaginative solutions required to address them. Quickly analyzing data keeps the analytic momentum going at the speed needed to engage organic exploration of the problem. 

Imagine an education consultant working with a school district to measure the effect of a new math intervention. The superintendent wants to compare quiz scores across schools. If the consultant can rapidly produce repeatedly reports for discussion, conversations can begin and continue with even more questions.

Quickly summarizing a teacher's latest batch of quiz scores and then returning for discussion should feel like a fast-paced and inspiring conversation with a collaborator. Contrast this with sluggish correspondence resulting from slow analysis. In these cases, the teacher's research question might've changed by the time the consultant returns with the data summary. 

You have an opportunity to provide speedy data analyses that sparks more and more important analytic questions. Thinking again about the consultant analyzing quiz scores, it's not hard to imagine new questions arising from rapid cycles of analysis:

 - How big was the effect of the new intervention, if any? 
 - Are there similar effects across student groups? 
 - Are there similar effects across grade levels? 

The trick here is to use statistics, programming, and content knowledge to raise and answer the right questions quickly so the process feels like a conversation. When there's too much time between analytic questions and their answers, educators lose the momentum required to follow the logical and exploratory path towards understanding student success. 

#### Example: Preparing Quiz Data to Compute Average Scores

Go back to the imaginary consultant tasked with computing the average quiz scores. Imagine the school district uses an online quiz system and each teacher's quiz export looks like this:

```{r make quiz data, message=FALSE}
library(tidyverse)
set.seed(2020)

quizzes_1 <- tibble(
    teacher_id = 1, 
    student_id = c(1:3), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE)
)

quizzes_1
```

Spreadsheets can help you compute mean quiz scores or mean student scores quickly. But what if you'd like to do that for not one, but five teachers? First, tidy the data. This will prepare the data nicely computing a variety of scores, including the mean. Start by using `pivot_longer()` to separate each student's quiz number and its score: 

```{r tidy quiz scores}
quizzes_1 %>% 
    pivot_longer(cols = quiz_1:quiz_3, names_to = "quiz_number", values_to = "score")
```

In the original dataset, each row represents a unique combination of teacher and student. After using `pivot_longer()`, each row now represents a unique combination of teacher, student, and quiz number. 

Data scientists describe this transformation as going from "wide" to "narrow." That's because of the change in the dataset's width. The benefit comes from the ability to group values by any of the columns. For example, here is how you'd group the scores by `student_id` and compute the mean:

```{r mean quiz scores}
quizzes_1 %>% 
    pivot_longer(cols = quiz_1:quiz_3, names_to = "quiz_number", values_to = "score") %>%
    group_by(student_id) %>% 
    summarise(quiz_mean = mean(score))
```

You can use this technique to compute the mean test score across multiple teachers. Start by creating two more datasets. To make the example more authentic, add a column to show if a student received an instructional intervention. 

```{r make more quiz exports with intervention}
# Add intervention column to first dataset 
quizzes_1 <- quizzes_1 %>% 
    mutate(intervention = sample(c(0, 1), 3, replace = TRUE))

# Second imaginary dataset
quizzes_2 <- tibble(
    teacher_id = 2, 
    student_id = c(4:6), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE), 
    intervention = sample(c(0, 1), 3, replace = TRUE)
)

# Third imaginary dataset
quizzes_3 <- tibble(
    teacher_id = 3, 
    student_id = c(7:9), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE), 
    intervention = sample(c(0, 1), 3, replace = TRUE)
)
```

Use this method to compute the mean quiz score for each student: 

1. Combine all datasets into one: Use `bind_rows()` to combine all three quiz exports into one dataset. This can be done because each teacher's export uses the same number of columns and column names 

1. Reuse the code from the first dataset on the new combined dataset: Paste the code used in the first example into the script so it cleans and computes the mean quiz score for each student 

```{r combine datasets}
# Use `bind_rows` to combine the three quiz exports into one big dataset
all_quizzes <- bind_rows(quizzes_1, quizzes_2, quizzes_3) 
```

Note there are now nine rows, one for each student across all three teacher quiz exports: 

```{r view combined datasets}
all_quizzes
```

Use the same approach you used when doing this for one teacher:

```{r mean student quiz score}
# Reuse the code from the first dataset on the new bigger dataset
all_quizzes %>% 
    # Clean with pivot_longer
    pivot_longer(cols = quiz_1:quiz_3, names_to = "quiz_number", values_to = "score") %>%
    # Compute the mean of each student
    group_by(student_id, intervention ) %>% 
    summarise(quiz_mean = mean(score))
```

Note that the hypothetical consultant is thinking ahead by including the `intervention` column. By doing so, she's preserved the possibility of exploring possible score differences between the students who had the intervention and the students who did not. Thinking ahead in this way builds conversation starters into your collaborations. If you can anticipate your client's questions, you'll be able to respond faster if and when these questions arise.

Comparing using R and spreadsheets, there may be little difference in the time it takes to do this for three quiz exports. But the gains in speed when computing over many datasets---say, 30 quiz exports---is truly useful. 

#### Summary

Learning how to rapidly answering analytic questions is not a silver bullet (but really, what is?). But it can put you on the path to creative solutions. It works something like this: 

 1. Rapidly answering analytic questions empowers you to help more people
 1. Helping more people creates more chances to practice your analytic skills
 1. Helping more people also creates more chances for clients to see the value of data science
 1. These two things—increased practice and a growing sense of value—nurtures confidence 
 1. Confidence encourages experimentation and creativity when developing solutions for students

Here are more ways to get faster: 

 - Notice when you use the same or similar chunks of code to do repetitive tasks. Store that code in a script so you can use it again
 - Keep a notebook of questions your clients ask you. Review them to develop an instinct for what teachers and administrators need. Anticipate these needs in your analysis and code
 - Where possible, avoid writing separate scripts for each dataset. Instead, learn to use functions and packages like {purrr} to write reusable operations for many datasets
 - Avoid the perfection trap when writing code. Instead, write first draft scripts and show the output to clients. They can give feedback early that informs your work going forward 

### Working with more data

When data analysts create more data for their clients, they give them more opportunities to learn what helps their students. In this regard, R is helpful because functions, loops, and scripts work on many datasets in the same time it takes to work on one.

For example, imagine a teacher whose students have an average quiz score of 75%. This helpful to know because it shows her how close her students are to some pre-determined standard, say 95%. But that data alone doesn't tell the teacher how similar or different her class average is from other classrooms. For that, you need context. 

Now imagine applying the same script used to compute this teacher's average quiz score to every classroom in the school. And imagine the school average quiz score was 77%. From this, the teacher learns her class average is similar to other classrooms. This is important nuance for developing her improvement strategy.

This example shows how working with scripts super charges your analysis. Using spreadsheets to work with large datasets, say 10,000 rows, requires you to interact directly with the user interface. That includes lots of scrolling, highlighting, and clicking that isn't saved for future use. In contrast, using a programming language with large datasets empowers you to issue complex and repeatable instructions to act on the data.

#### Example: replacing many student names with mumerical IDs

Say, for example, an elementary school administrator wants to replace each students' name in a classroom dataset with a numerical ID. Doing data entry in a spreadsheet for one classroom is feasible. Doing it for a all classrooms in a school requires a different approach. Instead of the administrator entering unique IDs into a spreadsheet, they can write an R script that executes these steps: 

 1. Use `read_csv()` to read every classroom's student list into R
 1. Use `bind_rows()` to combine the separate lists into one long list 
 1. Use `mutate()` to replace student names with a randomized and unique numerical ID 
 1. Use `split()` to separate the data into classrooms again 
 1. Use {purrr} and `write_csv()` to create and rename individual spreadsheets before sending back to teachers 

With some initial investment in coding time at the start, the administrator will have a script they can reuse in the future to do the task again.

##  Other ways to reimagine the scale of your work

### Reflect on your current scale, then push to the next level

When you've been using the same data analysis tools and routines for a long time, it's easy to forget to reflect on how you work. The analytic questions we ask, the datasets we use, and the scale of the analytic questions become automatic because for the most part, they've delivered results. When you introduce data science techniques and R into your education analysis workflow, you also introduce an opportunity to ask yourself: How can I put this analytic question in context by analyzing it on a larger scale? 

When an education client or coworker asks for help answering an analytic question, consider the following: 

 1. At what level is this question about, student, classroom, school, district, regional, state, or federal? 
 1. What can we learn by answering the analytic question at the current level, but also at the next level of scale-up?

If a teacher asks you to analyze the attendance pattern of one student, see what you learn by comparing it to the attendance pattern of the whole classroom or the whole school. If a superintendent of a school district asks you to analyze the behavior referrals of a school, analyze the behavior referrals of every school in the district. One of the many benefits of using programming languages like R to analyze data is that once you write code for one dataset, it can be used with many datasets with a relatively small amount of additional work. 

### Look for lots of similarly structured sata 

Train your eyes to be alert to repositories that contain many datasets that have the same structure, then design ways to act on all those datasets at once. Data systems in education generate standardized data tables all the time. It's one of the side effects of automation. Software developers design data systems to automatically generate many datasets for many people. The result is many datasets that contain different data, but all have the same number of columns and the same column names. This uniformity creates the perfect condition for R scripts to automatically act on these datasets in a way that is predictable and repeatable. Imagine a student information system that exports a list of students, their teacher, their grade level, and the number of school days attended to date. School administrators that have a weekly routine of exporting this data and storing it in a folder on their laptop will generate many uniformly structured datasets. When you train your eyes to see this as an opportunity to act on a lot of data at once, you will find an abundance of chances to transform data on a large scale so school staff can freely explore and ask questions aimed at improving the student experience. 

### Cleaning data

Folks who work in education want to look at data about their students with tools like Excel, but the data is frequently not ready for analysis. You can empower these folks to explore data and ask more questions by being alert to opportunities to prepare lots of data for analysis. Offer to clean a dataset! Then do it again and do it fast. When you get into this habit, you not only train your data cleaning skills but also train your education client's expectations for how quickly you can prepare data for them. 

## Solving problems together 

Steven Spielberg said, 

>When I was a kid, there was no collaboration; it's you with a camera bossing your friend around. But as an adult, filmmaking is all about appreciating the talents of the people you surround yourself with and knowing you could never have made any of these films by yourself
>
>`r tufte::quote_footer('--- [@nytimes2011]')`

Data science techniques are a powerful addition to an educational organization's problem-solving capacity. But  when you're the only person who codes or fits statistical models, it's easy to forget that the best solutions magically arrive when many perspectives come crashing together. Here are some things to think about as you challenge yourself to introduce data science to your education work in a lasting and meaningful way. 

### Data science in education and empathy 

One definition of empathy is seeing things as others do, which points to a barrier to our mission of discovering ways to use our data science skills to improve the experience of learners---it is all too easy to assume that our coworkers will be inspired by possibilities of data science as you are. In 1990, Elizabeth Newton, then a Stanford University graduate, asked research subjects to "tap" out well-known songs with their fingers and estimate how many people would recognize the songs [@newton1991, Heath and Heath 2006]. She found that they overestimated every time! When we know a subject well, we tend to forget the experience of not knowing that subject. So how do we make use of this knowledge? 

First, listen carefully to your coworkers as they work with data. As you listen, aim to understand the thinking process they use when making sense of reports, tables, and graphs. This will help you understand the problems and solutions they gravitate towards. 

Second, ask them if you can "borrow the problem" for a bit. "Borrowing a problem" is not solving it for them, it's using a little data science magic to get them unstuck so they can continue solving the problem the way they want to. If they're struggling to make a scatter plot from their pivot table data, offer to help by cleaning and summarizing the dataset before they try again. 

Third, if your first attempt at borrowing the problem didn't help, make an effort to learn more. Doing data science together is a conversation, so ask them how it went after you cleaned the dataset. Then listen, understand, and try again. After many rounds of this process, you may find your coworkers willing to try new methods for advancing their goals. 

A workplace going from not using data science to using data science regularly is a process that takes longer than you think. Responses to new ideas might include excitement and inspiration, but they might just as likely include resistance and fear. Changing the way an organization works requires new skills which often take years to learn. But here we are talking about one part of this change that is easily missed: listening to people and the system and using empathy to determine the unique place in your education organization that your data science skills will help students the most. Introducing data science techniques to your system is as much about having good people skills and empathy as it is about learning how to code and fit models. 

Data scientists and non-data scientists in education are similar in this regard---they both get excited and inspired by solving meaningful problems for their students. Once we recognize that that is the unifying goal, the exploration of how we do that with a diversity of expertise and tools begins. When we use empathy to connect with our coworkers about the common problems we are solving, we open the door to all kinds of solutions. Data science in education becomes a tool for a student-centered common cause, not an end in and of itself. 

Here are some reflection questions and exercises to use to inspire connection in your education workplace. Practice these questions both as personal reflections and also as questions you ask your coworkers: 

 1. What does data analysis in our organization look like today? 
 1. How do I wish data analysis will look like in the future?
 1. What is the hardest challenge I face in building my vision of student learning?
 1. What is one story about a rewarding experience I had with a student? 

### Create a daily practice commitment that answers someone else's question

In his book *Feck Perfuction*, designer @victore2019 writes,
>Success goes to those who keep moving, to those who can practice, make mistakes, fail, and still progress. It all adds up. Like exercise for muscles, the more you learn, the more you develop, and the stronger your skills become
>
> `r tufte::quote_footer('--- p. 31')` 

Doing data science is a skill and like all skills, repetition and mistakes are their fuel for learning. But what happens if you are the first person to do data science in your education workplace? When you have no data science mentors, analytics routines, or examples of past practice, it can feel aimless, to say the least. The antidote to that aimlessness is to practice daily.

Commit to writing code every day. Even the simplest three-line scripts have a way of adding to your growing programming instincts. Train your ears to be radars for data projects that are usually done in a spreadsheet, then take them on and do them in R. Need the average amount of time a student with disabilities spends in speech and language sessions? Try it in R. Need to rename the columns in a student quiz dataset? Try it in R. The principal is hand assembling 12 classroom attendance sheets into one dataset? You get the picture. 

Now along the path of data science daily practice you may discover that your non-data science coworkers start kindly declining your offers for help. In my experience there is nothing mean happening here, but rather this is a response to imagining what it's like to do what you are offering to do using the more commonly found spreadsheet applications. As your programming and statistics skills progress, some of the tasks you offer to help with will be the kind that, if done in a spreadsheet app, are overwhelmingly difficult and time-intensive. So in environments where programming is not used for data analysis, declining your offers of help are more perceived acts of kindness to you and probably not statements about the usefulness of your work. As frustrating as these situations might be, they are necessary experiences as an organization learns just how available speed and scale of data analysis are when you use programming as a tool. These are opportunities you should seize because they serve both as a daily practice and as demonstrations of the speed and scale programming for data analysis provides. 

### Build your network 

It is widely accepted that participating in personal and professional networks is important for surviving, thriving, and innovating. The path to connecting to a data science in education network is apparent if your education workplace has an analytics department, but it will take a little more thought if you are the lone data scientist. When looking for allies that will inspire and teach you, the mind immediately searches for other programmers and statisticians. These are relationships that will help you and the organization grow in its analytic approach. 

What the authors argue here is that data science in education is not just about bringing programming and statistics, but in the broader view is about evolving the whole approach to analytics. When viewed that way, members of a network broaden beyond just programmers and statisticians. It grows to include administrators and staff who are endlessly curious about the lives of students, graduate students fascinated with unique research methodologies, and designers who create interesting approaches to measurement. 

Networks for growing data science in education are not limited to the workplace. There are plenty of online and real-life chances to participate in a network that is just as rewarding as the networks you participate in during regular work hours. Here are a few to check out: 

 - Communities on Twitter like #R-Ladies and #rstats 
 - Local coding communities 
 - Conferences like rstudio::conf and useR! 
 - Online forums like RStudio Community 

## For K-12 teachers 

We've used almost all of this chapter to explore what to think about and what to do to help you bring your data science skills to your education workplace. So far the discussion has been from the data scientist's point of view, but what if you are one of the many who have an interest in analytics but very little interest in programming and statistics? Teachers in elementary and high schools are faced with a mind-boggling amount of student data. A study by @dataqualitycampaign2018 estimated that "95 percent of teachers use a combination of academic data (test scores, graduation rates, etc.) and nonacademic data (attendance, classroom, behavior, etc.) to understand their students' performance". 57% of the teachers in the study said a lack of time was a barrier to using the data they have. Data literacy is also increasingly important within teacher preparation programs [@mandinach2013].

Yet the majority of teachers aren't interested in learning a programming language and statistical methods as a way to get better at analytics, and both time and professional development for working with data are necessary [@datnow2015]. After all, most teachers chose their profession because they love teaching, not because they enjoy cleaning datasets and evaluating statistical model output. But to leave them out feels like a glaring omission in a field where perhaps the most important shared value is the effective teaching of students. 

If you do happen to be an elementary or high school teacher who wants to use programming and statistics to improve how you use data, you will find the approaches in this book useful. But if you are not that person, there is still much to explore that will lead to a rewarding experience as you grow your analytic skill. This book lacks the scope to explore this topic thoroughly, but there are many ways to improve how you use data without requiring a programming language or deep knowledge of statistics. 

For example, you can explore what is perhaps the most important element of starting a data analysis: asking the correct question. Chapter three of *The Art of Data Science* [@peng2015] provides a useful process for getting better at asking data questions. 

Given how often data is served to us through data visualizations, it is important to learn the best ways to create and consume these visualizations. Chapter one of the book *Data Visualization: A Practical Introduction* [@healy2019] explores this topic using excellent examples and writing. 

For practical applications of a data-informed approach, *Learning to Improve: How America's Schools Can Get Better at Getting Better* [@bryk2015] offers a thorough explanation of the improvement science process. The book is filled with examples of how data is used to understand problems and trial solutions. 

The final recommendation for elementary and secondary teachers wanting to get better at analysis is this: find, and partner with, someone who can help you answer the questions you have about how to serve your students better. You have the professional experience to come up with the right ideas and the curiosity to see what these ideas look like in the classroom. Inviting someone who can collaborate with you and help you measure the success of your ideas can be a rewarding partnership for you and your students. 
