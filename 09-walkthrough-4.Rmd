---
title: 'Education Dataset Analysis Pipeline: Walk Through #4'
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)
here::set_here(path = "~/documents/data-science-in-education")
```

## Background

Relationships are important to us. In the case of many research techniques, relationships are--deservedly--the focus of analyses. It is not very difficult to imagine *qualitative* techniques to study relationships: One could ask other individuals about who their friends are, why they are their friends, and what they like to do when with them. 

Increasingly, it is also not hard to imagine *quantitative* techniques to study relationships, too. In a way, the same questions that could be used qualitatively can serve as the basis for the quantitative study of relationships. Indeed, social network analysis uses these relations in a range of visualizations as well as statistical models.

Let us first consider visualizations.

<!-- Add example visualization here using ggraph? and ideas for how to create and modify visualizations -->

Visualizations of social networks are interesting and powerful--and increasingly common.

Behind these visualizations, though, there are also statistical models and methods that can help to understand what is going on with respect to particular relationships in a network in additional ways.

## Selection and influence

One way to consider these models and methods is in terms of two *processes* at play in our relationships (cite). These two processes are commonly (though not exclusively) the focus of statistical analyses of networks. In addition to not being exclusive, they do not interact independently: they affect each other reciprocally (Xu, Frank, & Penuel, 2018). They are:

- Selection: the processes regarding who chooses to have a relationship with whom
- Infuence: the processes regarding how who we have relationships with affects our behavior

While these are complex, they can be studied with the type of data collected from asking people about their relationships (and possibly asking them about or studying their behavior--or measuring some outcome). Happily, the use of these methods has expanded along with **R**: many of the best tools for studying social networks are in the form of long-standing R packages. Additionally, while there are many potential naunces to studying selection and influence, these are models that can fundamentally be carried out with regression, or the linear model (or extensions of it)

In this walkthrough, the influence model is the focus. Nevertheless, we provide some direction for how to carry out selection modeling, too, at the end. 

## An example of influence

In this example, we create some example data that can be used to explore questions about how influence works. Note that Joshua Rosenberg and Sarah Galey initially wrote the following code for a walkthrough shared on Ken Frank's website [here](https://msu.edu/~kenfrank/resources.htm).

### Creating example data in the form of an edgelist 

First, let's create three different data frames. Here is what they should contain:

- A data frame indicating who the *nominator* and *nominee* for the relation (i.e., if Stefanie says that José is her friend, then Stefanie is the nominator and José the nominee) - as well as an optional variable indicating the weight, or strength, of their relation
    - This data frame and its type can be considered the basis for many types of social network analysis and is a common structure for network data: it is an *edgelist*
- Data frames indicating the values of some behavior - an outcome - at two different time points

We use the **simstudy** package to simulate the data (and the **dplyr** package to process the data a bit).

Let's first generate `data1`.

```{r}
library(tidyverse)

create_yvar2 = function(yv1) {
  # Creates yvar2 as a linear outcome of yvar1 
  # Args: 
  #   yv1: yvar1
  yv1 * .25 + rnorm(n = 1, mean = 10, sd = 100)
}

#------------------------------------------------------------------------------

# Make the dataset 
high_y_values <- tibble(
  yvar1 = sample(1000:10000, 100, replace = TRUE)) %>% 
  mutate(yvar2 = map_dbl(yvar1, create_yvar2))

```

```{r}
library(simstudy)

set.seed("20190101")

def <- defData(varname = "nominator", dist = "categorical", formula = catProbs(n = 200)) 
def <- defData(def, varname = "nominee", dist = "categorical", formula = catProbs(n = 200))
def <- defData(def, varname = "relate", dist = "nonrandom", formula = 1)

data1 <- genData(500, def)
data1
```

`data2`:

```{r}
unique_nominators <- unique(data1$nominator) # need these to determine how many rows to generate
unique_nominees <- unique(data1$nominee)

def <- defData(varname = "yvar1", dist = "normal", formula = 2, variance = 2)

data2 <- genData(length(unique_nominees), def)
data2 <- data2 %>% 
    mutate(nominee = unique_nominees) %>% 
    select(nominee, yvar1)
```

And `data3`:

```{r}
def <- defData(varname = "yvar2", dist = "normal", formula = 5, variance = 2)

data3 <- genData(length(unique_nominators), def)
data3 <- data3 %>% 
    mutate(nominator = unique_nominees) %>% 
    select(nominator, yvar2)
```

### Joining the data

Next, we'll join the data into one data frame. Note that while this is sometimes tedius and time-consuming, especially with large sources of network data, it is a key step for being able to carry out network analysis - often, even for creating visualiations that are informative.

```{r}
library(dplyr)

data <- left_join(data1, data2, by = "nominee")
data$nominee <- as.character(data$nominee) # this makes merging later easier

# calculate indegree in tempdata and merge with data
tempdata <- data.frame(table(data$nominee)) # this needs to be calculated differently
names(tempdata) <- c("nominee", "indegree") # rename the column "nominee"
tempdata$nominee <- as.character(tempdata$nominee) # makes nominee a character data type, instead of a factor, which can cause problems
data <- left_join(data, tempdata, by = "nominee")
```

Let's take a look at the merged data. What this data now contains is the first data frame, `data1`, with each nominees' outcome at time 1 (`yvar1`). Note that we will find each nominators' outcome at time 2 later on.

```{r}
data <- as_tibble(data)
data
```

### Calculating an exposure term

This is the key step that makes this model - a regression, or linear, model - one that is special. It is creating an exposure term. The idea is that the exposure term "captures" how your interactions with someone, over some period of time (between the first and second time points) impact some outcome. This model accounts for an individual's initial report of the outcome, i.e., their time 1 prior value, so it is a model for *change* in some outcome.

```{r}
# Calculating exposure
data$exposure <- data$relate * data$yvar1

# Calculating mean exposure
mean_exposure <- data %>%
    group_by(nominator) %>%
    summarize(exposure_mean = mean(exposure))

```

What this data frame - `mean_exposure` - contains is the mean of the outcome (in this case, `yvar1`) for all of the individuals the nominator had a relation with.

As we need a final data set with `mean_exposure`, `mean_exposure_plus`, `degree`, `yvar1`, and `yvar2` added, we'll process the data a bit more.

```{r}
mean_exposure_terms <- left_join(mean_exposure, mean_exposure_plus, by = "nominator")

names(data2) <- c("nominator", "yvar1") # rename nominee as nominator to merge these
final_data <- left_join(mean_exposure_terms, data2, by = "nominator")
final_data <- left_join(final_data, data3, by = "nominator") # data3 already has nominator, so no need to change
```

### Regression (linear models)

Calculating the exposure term is the most distinctive and important step in carrying out influence models. Now, we can simply use a linear model to find out how much relations - as captured by the influence term - affect some outcome.

```{r}
model1 <- lm(yvar2 ~ yvar1 + exposure_mean, data = final_data)
summary(model1)
```

Note that these models show ...

<!-- Will want to interpret using the (needs-to-be) simulated data -->

So, the influence model is used to study a key process for social network analysis, but it is one that is useful, because you can quantify, given what you measure and how you measure it, *the network effect*, something that is sometimes not considered, especially in education (Sweet, 2017). It's also fundamentally a regression. That's really it, as the majority of the work goes into calculating the exposure term.

## Selection models

While this tutorial focused on influence models, selection models are also commonly used - and are commonly of interest not only to researchers but also to administrators and teachers (and even to youth and students). 

Here, we briefly describe a few possible approaches for using a selection model.

At its core, the selection model is a regression - albeit, one that is a generalization of one, namely, a logistic regression (sometimes termed a generalized linear model, because it is *basically* a regression but is one with an outcome that consists just of 0's and 1's). Thus, the most straight-away way to use a selection model is to use a logistic regression where all of the relations (note the `relate` variable in `data1` above) are indicated with a 1. But, here is the important and challenging step: all of the *possible relations* (i.e., all of the relations that are possible between all of the individuals in a network) are indicated with a 0 in an edgelist. Note that, again, an edgelist is the preferred data structure for carrying out this analysis. This step involves some data wrangling, especially the idea of widening or lengthening a data frame.

<!-- May want to add a short bit of code on this using `gather()` and `spread()` -->

Once all of the relations are indicated with a 1 or a 0, then a simple linear regression can be used. Imagine that we are interested in whether individuals from the *same* group are more or less likely to interact than those from different groups; same could be created in the data frame based upon knowing which group both nominator and nominee are from:

```{r, eval = FALSE}
m_selection <- glm(relate ~ 1 + same, data = edgelist1)
```

While this is a straightforward way to carry out a selection model, there are some limitations to it. Namely, it does not account for individuals who send more (or less) nominations overall--and not considering this may mean other effects, like the one associated with being from the *same* group, are not accurate. A few extensions of the linear model - including those that can use data for which relationships are indicated with weights, not just 1's and 0's, have been developed. 

One type of model extends the logistic regression. It can be used for data that is not only 1's and 0's but also data that is normally distributed or has fixed-ranks. It is the **amen** package available [here](https://cran.r-project.org/web/packages/amen/index.html).

A particularly common one is an Exponential Random Graph Model, or an ERGM. An R package that makes estimating these easy is available [here](https://cran.r-project.org/web/packages/ergm/index.html). That R package, **ergm**, is part of a powerful and often-used collection of packages, including those for working with network data (data that can begin with an edgelist, but may need additional processing that is challenging to do with edgelist data), **statnet**. A link to the statnet packages is [here](https://statnet.org/).